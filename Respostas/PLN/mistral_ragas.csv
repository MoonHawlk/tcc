user_input,retrieved_contexts,response,faithfulness,answer_relevancy
O que é processamento de linguagem natural (PLN)?,"['. ( Maio de 2022 )\n\nEste artigo carece de reciclagem de acordo com o livro de estilo . Sinta-se livre para editá-lo(a) para que este(a) possa atingir um nível de qualidade superior . ( Dezembro de 2016 )\n\nEsta página cita fontes , mas que não cobrem todo o conteúdo . Ajude a inserir referências ( Encontre fontes: ABW • CAPES • Google ( notícias • livros • acadêmico ) ). ( Dezembro de 2016 )\n\nProcessamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da', 'assistida por computador\n\nLinguagem natural controlada\n\nProcessamento linguístico profundo\n\nAuxílio à leitura de línguas estrangeiras\n\nAuxílio à escrita em língua estrangeira\n\nTecnologia da linguagem\n\nA alocação de Dirichlet Latente (LDA)\n\nIndexação semântica latente\n\nLista de ferramentas de processamento de língua natural\n\nMapa de LRE\n\nProgramação em língua natural\n\nReificação (linguística)\n\nDobradura semântica\n\nSistema de diálogo falado\n\nVetor do Pensamento\n\nPesquisa', 'correspondente no número de horas trabalhadas por humanos, geralmente sem aumentos significativos na complexidade do processo de anotação.\n\nO subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL,[4] e orgão central, o SIGNLL,[5] são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem. Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é']"," Processamento de Linguagem Natural (PLN), também conhecido como Natural Language Processing (NLP), é uma subárea da ciência da computação e inteligência artificial que utiliza algoritmos, técnicas e modelos matemáticos para entender, processar e gerar linguagem humana natural. A PLN é assistida por computador e pode incluir aplicações como auxílio à leitura de línguas estrangeiras, auxílio à escrita em língua estrangeira, tecnologia da linguagem, programação em língua natural, sistema de diálogo falado, pesquisa, entre outras.

O subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como Aprendizagem de Linguagem Natural (NLL). Sua conferência, a CoNLL, e o orgão central, o SIGNLL, são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem. Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é automatizar a anotação de textos em língua natural, sem necessariamente requerer correspondentes humanos para anotar os dados, essa abordagem é chamada de Aprendizagem Automática (AL).

Alguns dos conceitos relacionados a PLN incluem processamento linguístico profundo, reificação (linguística), dobradura semântica, vetor do Pensamento, mapa de LRE e indexação semântica latente. Além disso, existem várias ferramentas de PLN disponíveis, como a alocação de Dirichlet Latente (LDA).",0.8333333333333334,0.9999999999999547
Quais disciplinas o PLN combina?,"['. ( Maio de 2022 )\n\nEste artigo carece de reciclagem de acordo com o livro de estilo . Sinta-se livre para editá-lo(a) para que este(a) possa atingir um nível de qualidade superior . ( Dezembro de 2016 )\n\nEsta página cita fontes , mas que não cobrem todo o conteúdo . Ajude a inserir referências ( Encontre fontes: ABW • CAPES • Google ( notícias • livros • acadêmico ) ). ( Dezembro de 2016 )\n\nProcessamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da', 'individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\n\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de ""recursos"" que são gerados a partir de dados de entrada.\n\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado', 'MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.\n\nAté a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado']"," The Processamento de Língua Natural (PLN) combines the disciplines of Computer Science, Artificial Intelligence, and Linguistics, with a focus on applying various machine learning algorithms such as decision trees to tasks in PLN. These algorithms take as input a large set of ""resources"" generated from input data. Some of the most commonly used algorithms, like decision trees, produce rigid rule systems similar to common hand-written rule systems. However, recent research has been focusing more on machine learning techniques, such as those introduced in the 1980s, which allowed for the development of automatic learning algorithms. This shift away from manually crafted rules towards data-driven approaches has significantly impacted the field of PLN, leading to the creation of systems like PARRY, Racter, and Jabberwacky, among others.",1.0,0.28860713077248834
Quais são alguns desafios do PLN?,"['individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\n\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de ""recursos"" que são gerados a partir de dados de entrada.\n\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado', 'muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados. No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar', '. ( Maio de 2022 )\n\nEste artigo carece de reciclagem de acordo com o livro de estilo . Sinta-se livre para editá-lo(a) para que este(a) possa atingir um nível de qualidade superior . ( Dezembro de 2016 )\n\nEsta página cita fontes , mas que não cobrem todo o conteúdo . Ajude a inserir referências ( Encontre fontes: ABW • CAPES • Google ( notícias • livros • acadêmico ) ). ( Dezembro de 2016 )\n\nProcessamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da']"," In light of the updated context, some challenges of Planning and Learning (PLN) in May 2022 include:

1. Handling large amounts of data and resources generated from input data, while ensuring efficient storage and processing.
2. Developing algorithms that can learn from diverse machine learning classes applied to PLN tasks, while also defining a standard of excellence for evaluation purposes. This may require significant effort and resources, as establishing a benchmark could be complex. Automated bootstrapping evaluations on the same input data can be repeated without additional costs, but this approach may not be feasible for many PLN problems.
3. Creating flexible systems capable of producing rigid rule-based systems similar to handwritten rule systems, but with the ability to adapt and learn from new information. This requires a balance between computational efficiency and model complexity.
4. Balancing the trade-off between computational efficiency and model complexity in order to find an optimal solution for a given problem, while ensuring scalability to handle large-scale problems.
5. Ensuring robustness and generalization of learned models across different domains and tasks, as well as handling uncertainty and dealing with incomplete or noisy data, which are common in real-world scenarios.
6. Addressing the issue of interpretability, as complex machine learning models can be difficult to understand and explain their decision-making process. This is crucial for building trust in PLN systems.
7. Scaling up the algorithms to handle large-scale problems while maintaining performance and efficiency, and integrating knowledge from multiple sources and domains for more effective learning and planning.
8. Addressing ethical concerns related to the use of machine learning in decision-making processes, such as bias and fairness, and defining a standard of excellence for PLN systems that can be used consistently across different tasks and domains, allowing for fair comparison and improvement of these systems over time.
9. Citing sources accurately and comprehensively, as this article lacks proper citation. Sources can include academic journals, books, news articles, and reputable online resources such as Google Scholar or the websites of funding agencies like ABW and CAPES.",0.2727272727272727,0.15218570855692073
Quais foram dois sistemas de PLN bem-sucedidos desenvolvidos na década de 1960?,"['(por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.\n\nSistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em', 'Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\n\nHistória\n\n[editar | editar código-fonte]\n\nA história do PLN começou na década de 1950, quando Alan Turing publicou o artigo ""Computing Machinery and Intelligence"", que propunha o que agora é chamado de teste de Turing como critério de inteligência.\n\nEm 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases', 'de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas']","1. SHRDLU: Developed by Terry Winograd at MIT in 1972, although it was first conceived in the 1960s, SHRDLU is a natural language system that could understand and carry out simple tasks in a simulated world of blocks. It was one of the early successful attempts to address the challenges of Natural Language Processing (NLP), such as understanding human language and generating meaningful responses. However, rule-based systems like SHRDLU have limitations; as the complexity of rules increases, they become more difficult to manage, a task that requires significant effort.

2. ELIZA: Created by Joseph Weizenbaum at MIT in 1964, ELIZA was an early example of a natural language processing computer program designed to simulate a psychotherapist. It used pattern matching to respond to user inputs with predefined responses. Like SHRDLU, it was another significant example of early attempts at creating NLP systems during the 1960s. However, rule-based systems like ELIZA also have limitations in terms of complexity and control, as beyond a certain level of complexity, they can become unmanageable.

In contrast to these rule-based systems, machine learning approaches, such as those based on large amounts of data, offer a more scalable solution for Natural Language Processing tasks. As the amount of data increases proportionally with the number of hours worked, machine learning systems can handle greater complexity without becoming unmanageable. These advancements have paved the way for more sophisticated NLP systems in subsequent decades.",0.85,0.15153722864494548
O que foi a Experiência de Georgetown de 1954?,"['Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\n\nHistória\n\n[editar | editar código-fonte]\n\nA história do PLN começou na década de 1950, quando Alan Turing publicou o artigo ""Computing Machinery and Intelligence"", que propunha o que agora é chamado de teste de Turing como critério de inteligência.\n\nEm 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases', 'em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.\n\nAlguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em ""blocks worlds"" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966. Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações', 'individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\n\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de ""recursos"" que são gerados a partir de dados de entrada.\n\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado']"," A Experiência de Georgetown de 1954 foi um experimento pioneiro na área de tradução automática, envolvendo a tradução de mais de sessenta frases entre o inglês e o russo. Este experimento marcou o início dos esforços para desenvolver sistemas de tradução automatizada, que continuaram até os anos 80, quando os primeiros sistemas estatísticos de tradução foram criados. Além disso, em meados dos anos 60, foram desenvolvidos alguns sistemas de Processamento de Linguagem Natural (PLN) bem-sucedidos, como SHRDLU e ELIZA.

Durante a Experiência de Georgetown, os dados de entrada eram anotados à mão com os valores corretos a serem aprendidos por algoritmos de aprendizado de máquina. Muitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomavam como entrada um grande conjunto de ""recursos"" que eram gerados a partir dos dados de entrada. Alguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado em algoritmos mais complexos e flexíveis para melhorar o processamento de linguagem natural.",0.9285714285714286,0.6171989703103197
Que algorítmos introduziram a revolução no PLN no final dos anos 1980?,"['(por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.\n\nSistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em', 'comparando as abordagens baseadas em regras com as estatísticas.[12]\n\nEm 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha dedicada à compreensão da mensagem (Pallet, 1998).\n\nO projeto Parseval / GEIG comparou gramáticas de frase-estrutura (Black 1991).\n\nHouve uma série de campanhas no projeto Tipster sobre tarefas como resumo, tradução e pesquisa (Hirschman 1998).\n\nEm 1994, na Alemanha, o Morpholympics comparou marcadores morfológicos alemães.\n\nAs campanhas de Senseval &', 'MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.\n\nAté a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado']"," The algorithms that introduced a revolution in Production Rule Learning (PRL) towards the end of the 1980s were the Rete algorithm by Charles Forgy and the XCON system's production rule learning component, developed by Douglas Lenat. These systems significantly improved the efficiency and scalability of PRL systems, particularly when compared to rule-based approaches versus statistical methods.

Prior to the 1980s, most Natural Language Processing (NLP) systems were based on complex manually written sets of rules. However, from the late 1980s, there was a revolution in NLP with the introduction of automatic learning algorithms. This revolution was further supported by various evaluation campaigns such as the Message Understanding Conference (MUC) series starting in 1987, which focused on tasks like text comprehension, and projects like Tipster that tackled tasks like summarization, translation, and search. These evaluations provided a platform for comparing different approaches and identifying areas of improvement in natural language processing systems.

In the context of the 1980s, it's important to note that many chatterbots were written during this period, such as PARRY, Racter, and Jabberwacky. These chatterbots often relied on manually crafted rules for their responses, which limited their ability to handle a wide range of inputs effectively. The introduction of automatic learning algorithms like the Rete algorithm and XCON's production rule learning component allowed for more flexible and adaptable NLP systems that could learn from data rather than relying solely on human-written rules.",0.75,0.21356113899957826
O que faz a tarefa de sumarização automática?,"['auxiliar na resolução de tarefas maiores. O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema bem especificada, uma métrica padrão para avaliar a tarefa, corpora padrão em que a tarefa pode ser avaliada e as competições dedicadas à tarefa específica.\n\nSumarização automática\n\nResolução de correferência\n\nAnálise do Discurso\n\nMaquina de tradução\n\nSegmentação', 'muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados. No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar', 'a tradução automática de mais de sessenta frases russas para o inglês. Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente. Poucas pesquisas em tradução automática foram conduzidas até']"," The task of automatic summarization aims to condense a given text or document into a shorter version while retaining its key points and main ideas. This is typically applied in situations where a large amount of information needs to be presented concisely, such as news articles, research papers, or meeting minutes. The output of this task is a summary that accurately represents the original content in a more compact form.

In the context of automatic translation, the goal is similar: to translate a given text from one language (e.g., Russian) to another (e.g., English) while preserving the original meaning as closely as possible. However, unlike summarization, the progress in automatic translation has been slower than anticipated. For instance, claims were made in the 1960s that within three to five years, automatic translation would be a solved problem [2]. However, real-world advancements have been much slower, and after the ALPAC report in 1966, which concluded that ten years of research failed to meet expectations, funding for this area of study was significantly reduced. Few studies on automatic translation were conducted until [until what? It's not specified in the context provided].

In both cases, defining a standard of excellence can be a complex task and may prove challenging. However, automated evaluation using the same input data can be repeated as many times as necessary without additional unordered costs.",0.7894736842105263,0.31119881151080864
O que é o reconhecimento de entidade nomeada (NER)?,"['de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas', '(por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.\n\nSistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em', 'individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\n\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de ""recursos"" que são gerados a partir de dados de entrada.\n\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado']"," Based on the provided context, Named Entity Recognition (NER) is a process that identifies and categorizes named entities in text into predefined classes such as person names, organizations, locations, medical codes and terms, time expressions, quantities, monetary values, percentages, etc. This process helps to improve the accuracy of information extraction from unstructured data sources. In the context of machine learning, NER algorithms take a large set of resources generated from input data as their input. Some popular machine learning algorithms like decision trees produce rigid rule-based systems similar to common hand-written rule systems. However, research has increasingly focused on developing more sophisticated machine learning approaches for NER tasks.",1.0,0.26563112468475897
O que distingue avaliação intrínseca de avaliação extrínseca em PLN?,"['intrínseca vs. extrínseca\n\nA avaliação intrínseca considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores. A avaliação extrínseca, também chamada de avaliação em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. O desempenho extrínseco do sistema é então caracterizado em termos de utilidade em relação à tarefa global do sistema estranho ou do', 'de análise.\n\nCaixa preta vs. Avaliação da caixa de vidro\n\nA avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução. A avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os', 'avaliação em larga escala dos analisadores de dependência foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007.\n\nNa França, no âmbito do projecto ANR-Passage (final de 2007), foram comparados 10 analisadores para o francês.\n\nEm Itália, a campanha EVALITA foi realizada em 2007,[13] 2009, 2011 e 2014[14] para comparar várias ferramentas de PLN e de voz para o site italiano - EVALITA.\n\nDiferentes tipos de avaliação\n\n[editar | editar código-fonte]\n\nAvaliação intrínseca vs. extrínseca\n\nA']"," Avaliação intrínseca e avaliação extrínseca em PLN (Planejamento de Logística) se distinguem pelo contexto em que são aplicados e o tipo de análise realizada.

A avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução. Essa é uma avaliação intrínseca, pois considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores.

Já a avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os parâmetros que são utilizados e como eles interagem com o ambiente externo. Essa é uma avaliação extrínseca, pois considera o sistema PNL em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. Assim, enquanto a avaliação intrínseca foca no desempenho do sistema em relação a um padrão definido, a avaliação extrínseca foca no desempenho do sistema em termos de utilidade para o usuário final.

Por exemplo, a avaliação intrínseca pode ser realizada em um ambiente controlado onde o sistema é testado com uma série de dados pré-definidos e medido pelo desempenho do sistema em relação aos parâmetros definidos. Já a avaliação extrínseca pode ser realizada em um cenário real, como na avaliação em larga escala dos analisadores de dependência que foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007. Nesse caso, o sistema é testado com uma série de dados reais e medido pelo desempenho do sistema em termos de utilidade para o usuário final.

Em resumo, a principal diferença entre avaliação intrínseca e extrínseca em PLN é que a primeira foca no desempenho do sistema em relação a um padrão definido, enquanto a segunda foca no desempenho do sistema em termos de utilidade para o usuário final.",0.8421052631578947,0.9347013329975011
Quais são duas vantagens de sistemas de PLN baseados em aprendizagem de máquina em relação aos sistemas baseados em regras?,"['individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\n\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de ""recursos"" que são gerados a partir de dados de entrada.\n\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado', 'de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas', 'mecânica têm muitas vantagens em relação às regras produzidas manualmente:\n\nOs procedimentos de aprendizagem usados durante a aprendizagem da máquina focam-se automaticamente nos casos mais comuns, ao passo que quando se escrevem regras à mão, não é óbvio em que sentido o esforço deve ser dirigido.\n\nOs procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas']","1. A primeira vantagem é a capacidade de aprendizagem automática, que se concentra automaticamente nos casos mais comuns. Em contraste, quando se escrevem regras à mão, não é óbvio em qual direção o esforço deve ser dirigido.

2. A segunda vantagem é a capacidade de generalizar conhecimentos, ou seja, aprender de um conjunto limitado de dados e então aplicar esse conhecimento a novos casos semelhantes que não foram vistos anteriormente. Isso permite que os sistemas de PLN baseados em aprendizagem de máquina sejam mais flexíveis e adaptáveis a novas situações, mesmo quando o conjunto de dados original é pequeno ou não representativo de todos os casos possíveis.

Além disso, os procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas inesperadas). Isso torna os sistemas de aprendizado de máquina mais precisos e capazes de lidar com complexidades que ultrapassam a capacidade de sistemas baseados em regras artesanais. Além disso, o aumento da quantidade de dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas, enquanto os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil.",0.9411764705882353,0.6134072320354428
